#!/usr/bin/env python3
"""
OpenAI ChatAPI çœŸå® API æµ‹è¯•è„šæœ¬

æ­¤è„šæœ¬ç”¨äºæµ‹è¯•ä¸çœŸå® API æ¥å£çš„è¿æ¥å’ŒåŠŸèƒ½ã€‚
è¿è¡Œå‰éœ€è¦ï¼š
1. è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY
2. ç¡®ä¿ API æ¥å£å¯è®¿é—®
3. ï¼ˆå¯é€‰ï¼‰é…ç½®è‡ªå®šä¹‰ base_url

ä½¿ç”¨æ–¹æ³•ï¼š
    # ä½¿ç”¨ç¯å¢ƒå˜é‡
    export OPENAI_API_KEY="your-api-key"
    python test_real_api.py

    # æˆ–åœ¨ä»£ç ä¸­è®¾ç½® API keyï¼ˆä¸æ¨èï¼‰
    python test_real_api.py --api-key "your-key"
"""

import asyncio
import argparse
import json
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

# ä½¿ç”¨åŒ…å¯¼å…¥ä»¥é¿å…ç›¸å¯¹å¯¼å…¥é”™è¯¯
from openai_chatapi.chat_agent import ChatAgent
from openai_chatapi.model_config import ModelConfig
from openai_chatapi.runtime_config import RuntimeConfig
from openai_chatapi.exceptions import APIConnectionError, APIResponseError


# ============================================================
# æµ‹è¯•é…ç½®
# ============================================================

class TestConfig:
    """æµ‹è¯•é…ç½®"""
    def __init__(self, api_key: str = None, base_url: str = None):
        self.api_key = api_key
        self.base_url = base_url
        self.test_model = "qwen3-8b"  # ä½¿ç”¨ qwen ç³»åˆ—æ¨¡å‹ä½œä¸ºé»˜è®¤
        self.test_timeout = 30.0


# ============================================================
# æµ‹è¯•ç”¨ä¾‹
# ============================================================

async def test_1_basic_connection(test_config: TestConfig):
    """æµ‹è¯• 1: åŸºç¡€è¿æ¥æµ‹è¯•"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 1: åŸºç¡€ API è¿æ¥")
    print("=" * 70)
    
    try:
        model_config = ModelConfig(
            api_key=test_config.api_key,
                api_base_url=test_config.base_url,
            model=test_config.test_model,
            max_tokens=50
        )
        
        runtime_config = RuntimeConfig(
            timeout=test_config.test_timeout,
            enable_debug=True
        )
        
        async with ChatAgent(model_config, runtime_config) as agent:
            print("å‘é€æµ‹è¯•æ¶ˆæ¯...")
            response = await agent.chat("ä½ å¥½ï¼Œè¯·å›å¤'æµ‹è¯•æˆåŠŸ'")
            
            print(f"\nå“åº”: {response}")
            print(f"\nç»Ÿè®¡ä¿¡æ¯:")
            stats = agent.get_stats()
            print(f"  - è¯·æ±‚æ¬¡æ•°: {stats['total_requests']}")
            print(f"  - Token ä½¿ç”¨: {stats['total_tokens']}")
            print(f"  - å¹³å‡å“åº”æ—¶é—´: {stats.get('average_latency', 0.0):.3f}s")
            
        print("\nâœ… åŸºç¡€è¿æ¥æµ‹è¯•é€šè¿‡")
        return True
        
    except Exception as e:
        print(f"\nâŒ åŸºç¡€è¿æ¥æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_2_multi_turn_conversation(test_config: TestConfig):
    """æµ‹è¯• 2: å¤šè½®å¯¹è¯"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 2: å¤šè½®å¯¹è¯ä¸ä¸Šä¸‹æ–‡ä¿æŒ")
    print("=" * 70)
    
    try:
        model_config = ModelConfig(
            api_key=test_config.api_key,
                api_base_url=test_config.base_url,
            model=test_config.test_model,
            max_tokens=100
        )
        
        async with ChatAgent(model_config) as agent:
            # è®¾ç½®ç³»ç»Ÿæç¤º
            agent.set_system_prompt("ä½ æ˜¯ä¸€ä¸ªæ•°å­¦åŠ©æ‰‹")
            
            # ç¬¬ä¸€è½®
            print("\nè½®æ¬¡ 1:")
            response1 = await agent.chat("è¯·è®°ä½ï¼šx = 5")
            print(f"ç”¨æˆ·: è¯·è®°ä½ï¼šx = 5")
            print(f"åŠ©æ‰‹: {response1}")
            
            # ç¬¬äºŒè½®
            print("\nè½®æ¬¡ 2:")
            response2 = await agent.chat("x çš„å€¼æ˜¯å¤šå°‘ï¼Ÿ")
            print(f"ç”¨æˆ·: x çš„å€¼æ˜¯å¤šå°‘ï¼Ÿ")
            print(f"åŠ©æ‰‹: {response2}")
            
            # éªŒè¯ä¸Šä¸‹æ–‡
            if "5" in response2:
                print("\nâœ… å¤šè½®å¯¹è¯æµ‹è¯•é€šè¿‡ï¼ˆä¸Šä¸‹æ–‡ä¿æŒæ­£ç¡®ï¼‰")
                return True
            else:
                print("\nâš ï¸  å¤šè½®å¯¹è¯æµ‹è¯•è­¦å‘Šï¼ˆä¸Šä¸‹æ–‡å¯èƒ½æœªä¿æŒï¼‰")
                return False
                
    except Exception as e:
        print(f"\nâŒ å¤šè½®å¯¹è¯æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_3_streaming_output(test_config: TestConfig):
    """æµ‹è¯• 3: æµå¼è¾“å‡º"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 3: æµå¼è¾“å‡º")
    print("=" * 70)
    
    try:
        model_config = ModelConfig(
            api_key=test_config.api_key,
                api_base_url=test_config.base_url,
            model=test_config.test_model,
            max_tokens=100
        )
        
        async with ChatAgent(model_config) as agent:
            print("\nå¼€å§‹æµå¼è¾“å‡º:")
            print("-" * 70)
            
            # æ‰‹åŠ¨å¤„ç†æ¯ä¸ª chunkï¼ˆè¾ƒä¸ºç¨³å®šï¼‰
            print("æ‰‹åŠ¨å¤„ç†æµï¼Œæ¯ä¸ª chunk å°†è¢«æ‰“å°ï¼š")
            print("å“åº”: ", end="", flush=True)
            async for chunk in agent.chat_stream(
                "æ•°åˆ° 5",
                display_stream=False
            ):
                # chunk ä¸ºå­—ç¬¦ä¸²å†…å®¹ï¼Œç›´æ¥æ‰“å°
                print(chunk, end="", flush=True)
            print()
            
            print("\nâœ… æµå¼è¾“å‡ºæµ‹è¯•é€šè¿‡")
            return True
            
    except Exception as e:
        print(f"\nâŒ æµå¼è¾“å‡ºæµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_4_tool_calling(test_config: TestConfig):
    """æµ‹è¯• 4: å·¥å…·è°ƒç”¨"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 4: Function Calling (å·¥å…·è°ƒç”¨)")
    print("=" * 70)
    
    try:
        model_config = ModelConfig(
            api_key=test_config.api_key,
            api_base_url=test_config.base_url,
            model=test_config.test_model,
            max_tokens=200
        )

        runtime_config = RuntimeConfig()

        async with ChatAgent(model_config, runtime_config) as agent:
            # åŠ è½½å·¥å…·
            tool_json_path = Path(__file__).parent.parent / "tools" / "fake_tool.json"
            if not tool_json_path.exists():
                print("âš ï¸  å·¥å…·å®šä¹‰æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•")
                return None

            # åŠ è½½å¹¶æ³¨å†Œå·¥å…·
            with open(tool_json_path, 'r', encoding='utf-8') as f:
                tools_data = json.load(f)

            from openai_chatapi.schema import Tool, FunctionDefinition
            from openai_chatapi.tools.fake_tool import get_tool_function
            for tool_data in tools_data:
                func = tool_data.get("function")
                if isinstance(func, dict):
                    func_obj = FunctionDefinition(**func)
                else:
                    func_obj = None
                tool = Tool(type=tool_data.get("type", "function"), function=func_obj)
                # Try to attach a local handler if available
                handler = get_tool_function(func_obj.name) if func_obj else None
                agent.register_tool(tool, handler)

            print(f"å·²æ³¨å†Œ {len(agent.tools)} ä¸ªå·¥å…·")

            # æµ‹è¯•å·¥å…·è°ƒç”¨
            print("\nå‘é€éœ€è¦å·¥å…·çš„è¯·æ±‚...")
            response = await agent.chat(
                "å¸®æˆ‘æœç´¢ï¼šPython å¼‚æ­¥ç¼–ç¨‹",
                auto_execute_tools=True,
                max_tool_iterations=3
            )

            print(f"\næœ€ç»ˆå“åº”: {response}")

            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            tool_messages = [msg for msg in agent.messages if getattr(msg, "role", None) == "tool"]
            if tool_messages:
                print(f"\nâœ… å·¥å…·è°ƒç”¨æµ‹è¯•é€šè¿‡ï¼ˆè°ƒç”¨äº† {len(tool_messages)} æ¬¡å·¥å…·ï¼‰")
                return True
            else:
                print("\nâš ï¸  å·¥å…·è°ƒç”¨æµ‹è¯•è­¦å‘Šï¼ˆæœªæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼‰")
                return False

    except Exception as e:
        print(f"\nâŒ å·¥å…·è°ƒç”¨æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_5_multimodal_input(test_config: TestConfig):
    """æµ‹è¯• 5: å¤šæ¨¡æ€è¾“å…¥"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 5: å¤šæ¨¡æ€è¾“å…¥ï¼ˆå›¾ç‰‡ï¼‰")
    print("=" * 70)
    
    try:
        # æ³¨æ„ï¼šéœ€è¦æ”¯æŒè§†è§‰çš„æ¨¡å‹
        model_config = ModelConfig(
            api_key=test_config.api_key,
            api_base_url=test_config.base_url,
            model="qwen3-vl-8b-instruct",
            max_tokens=200
        )
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•å›¾ç‰‡
        test_image_path = Path(__file__).parent / "test_image.jpg"
        if not test_image_path.exists():
            print("âš ï¸  æµ‹è¯•å›¾ç‰‡ä¸å­˜åœ¨ï¼Œè·³è¿‡æµ‹è¯•")
            print(f"   è¯·å°†æµ‹è¯•å›¾ç‰‡æ”¾åœ¨: {test_image_path}")
            return None
        
        async with ChatAgent(model_config) as agent:
            print(f"ä½¿ç”¨å›¾ç‰‡: {test_image_path}")
            
            response = await agent.chat(
                "è¯·æè¿°è¿™å¼ å›¾ç‰‡",
                image_paths=[str(test_image_path)]
            )
            
            print(f"\nå“åº”: {response}")
            print("\nâœ… å¤šæ¨¡æ€è¾“å…¥æµ‹è¯•é€šè¿‡")
            return True
            
    except Exception as e:
        print(f"\nâŒ å¤šæ¨¡æ€è¾“å…¥æµ‹è¯•å¤±è´¥: {e}")
        print("   æ³¨æ„ï¼šæ­¤åŠŸèƒ½éœ€è¦æ”¯æŒè§†è§‰çš„æ¨¡å‹ï¼ˆå¦‚ gpt-4oï¼‰")
        return False


async def test_6_error_handling(test_config: TestConfig):
    """æµ‹è¯• 6: é”™è¯¯å¤„ç†"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 6: é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶")
    print("=" * 70)
    
    try:
        # ä½¿ç”¨æ— æ•ˆçš„ API key æµ‹è¯•é”™è¯¯å¤„ç†
        model_config = ModelConfig(
            api_key="invalid-key-for-testing",
                api_base_url=test_config.base_url,
            model=test_config.test_model
        )
        
        runtime_config = RuntimeConfig(
            max_retries=2,
            timeout=10.0
        )
        
        async with ChatAgent(model_config, runtime_config) as agent:
            try:
                await agent.chat("æµ‹è¯•æ¶ˆæ¯")
                print("\nâš ï¸  é”™è¯¯å¤„ç†æµ‹è¯•è­¦å‘Šï¼ˆåº”è¯¥æŠ›å‡ºå¼‚å¸¸ä½†æ²¡æœ‰ï¼‰")
                return False
            except (APIConnectionError, APIResponseError) as e:
                print(f"\nâœ… é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡ï¼ˆæ­£ç¡®æ•è·å¼‚å¸¸: {type(e).__name__}ï¼‰")
                return True
                
    except Exception as e:
        print(f"\nâŒ é”™è¯¯å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_7_parameter_override(test_config: TestConfig):
    """æµ‹è¯• 7: å‚æ•°è¦†ç›–"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 7: åŠ¨æ€å‚æ•°è¦†ç›–")
    print("=" * 70)
    
    try:
        model_config = ModelConfig(
            api_key=test_config.api_key,
                api_base_url=test_config.base_url,
            model=test_config.test_model,
            temperature=0.5,
            max_tokens=50
        )
        
        async with ChatAgent(model_config) as agent:
            # ä½¿ç”¨é»˜è®¤å‚æ•°
            print("\næµ‹è¯• 1: ä½¿ç”¨é»˜è®¤å‚æ•°")
            response1 = await agent.chat("è¯´ä¸€ä¸ªæ•°å­—")
            print(f"å“åº” 1: {response1}")
            
            # è¦†ç›–æ¸©åº¦å‚æ•°ï¼ˆæ›´éšæœºï¼‰
            print("\næµ‹è¯• 2: è¦†ç›–å‚æ•° (temperature=1.5)")
            response2 = await agent.chat(
                "è¯´ä¸€ä¸ªæ•°å­—",
                temperature=1.5,
                max_tokens=30
            )
            print(f"å“åº” 2: {response2}")
            
            print("\nâœ… å‚æ•°è¦†ç›–æµ‹è¯•é€šè¿‡")
            return True
            
    except Exception as e:
        print(f"\nâŒ å‚æ•°è¦†ç›–æµ‹è¯•å¤±è´¥: {e}")
        return False


async def test_8_statistics_tracking(test_config: TestConfig):
    """æµ‹è¯• 8: ç»Ÿè®¡è¿½è¸ª"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 8: Token ä½¿ç”¨å’Œç»Ÿè®¡è¿½è¸ª")
    print("=" * 70)
    
    try:
        model_config = ModelConfig(
            api_key=test_config.api_key,
                api_base_url=test_config.base_url,
            model=test_config.test_model,
            max_tokens=50
        )
        
        async with ChatAgent(model_config) as agent:
            # å‘é€å¤šä¸ªè¯·æ±‚
            for i in range(3):
                await agent.chat(f"æµ‹è¯•æ¶ˆæ¯ {i+1}")
            
            # è·å–ç»Ÿè®¡
            stats = agent.get_stats()
            
            print("\nç»Ÿè®¡ä¿¡æ¯:")
            print(f"  æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
            print(f"  æ€» Token: {stats['total_tokens']}")
            print(f"  å¹³å‡å“åº”æ—¶é—´: {stats.get('average_latency', 0.0):.3f}s")
            estimated_cost = stats.get('estimated_cost', None)
            if estimated_cost is not None:
                print(f"  é¢„ä¼°æˆæœ¬: ${estimated_cost:.6f}")
            else:
                print("  é¢„ä¼°æˆæœ¬: (æœªè®¡ç®—)")
            
            if stats['total_requests'] == 3:
                print("\nâœ… ç»Ÿè®¡è¿½è¸ªæµ‹è¯•é€šè¿‡")
                return True
            else:
                print("\nâš ï¸  ç»Ÿè®¡è¿½è¸ªæµ‹è¯•è­¦å‘Šï¼ˆè¯·æ±‚æ•°ä¸åŒ¹é…ï¼‰")
                return False
                
    except Exception as e:
        print(f"\nâŒ ç»Ÿè®¡è¿½è¸ªæµ‹è¯•å¤±è´¥: {e}")
        return False


# ============================================================
# ä¸»æµ‹è¯•å‡½æ•°
# ============================================================

async def run_real_api_tests(test_config: TestConfig, skip_expensive: bool = True):
    """è¿è¡ŒçœŸå® API æµ‹è¯•"""
    print("\n" + "=" * 70)
    print("OpenAI ChatAPI çœŸå® API æµ‹è¯•")
    print("=" * 70)
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"æµ‹è¯•æ¨¡å¼: çœŸå® API è°ƒç”¨")
    print(f"æµ‹è¯•æ¨¡å‹: {test_config.test_model}")
    if test_config.base_url:
        print(f"API åœ°å€: {test_config.base_url}")
    print("=" * 70)
    
    results = {}
    
    # å¿…è¦æµ‹è¯•ï¼ˆä½æˆæœ¬ï¼‰
    print("\nâ–¶ï¸  è¿è¡Œå¿…è¦æµ‹è¯•...")
    results['basic_connection'] = await test_1_basic_connection(test_config)
    results['multi_turn'] = await test_2_multi_turn_conversation(test_config)
    results['streaming'] = await test_3_streaming_output(test_config)
    results['tool_calling'] = await test_4_tool_calling(test_config)
    results['error_handling'] = await test_6_error_handling(test_config)
    results['parameter_override'] = await test_7_parameter_override(test_config)
    results['statistics'] = await test_8_statistics_tracking(test_config)
    
    # å¯é€‰æµ‹è¯•ï¼ˆå¯èƒ½éœ€è¦é¢å¤–èµ„æºï¼‰
    if not skip_expensive:
        print("\nâ–¶ï¸  è¿è¡Œå¯é€‰æµ‹è¯•...")
        results['multimodal'] = await test_5_multimodal_input(test_config)
    else:
        print("\nâ­ï¸  è·³è¿‡æ˜‚è´µæµ‹è¯•ï¼ˆå¤šæ¨¡æ€ï¼‰")
        print("   ä½¿ç”¨ --include-expensive å‚æ•°è¿è¡Œå®Œæ•´æµ‹è¯•")
        results['multimodal'] = None
    
    # æ€»ç»“
    print("\n" + "=" * 70)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 70)
    
    passed = sum(1 for v in results.values() if v is True)
    failed = sum(1 for v in results.values() if v is False)
    skipped = sum(1 for v in results.values() if v is None)
    total = len(results)
    
    print(f"æ€»æµ‹è¯•æ•°: {total}")
    print(f"âœ… é€šè¿‡: {passed}")
    print(f"âŒ å¤±è´¥: {failed}")
    print(f"â­ï¸  è·³è¿‡: {skipped}")
    
    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print(f"\nâš ï¸  {failed} ä¸ªæµ‹è¯•å¤±è´¥")
    
    print("=" * 70)
    
    # ä¿å­˜æµ‹è¯•æŠ¥å‘Š
    report_path = Path(__file__).parent / "test_report_real_api.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump({
            "timestamp": datetime.now().isoformat(),
            "mode": "real_api",
            "model": test_config.test_model,
            "results": {k: str(v) for k, v in results.items()}
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\næµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    
    return 0 if failed == 0 else 1


# ============================================================
# å‘½ä»¤è¡Œå…¥å£
# ============================================================

def main():
    parser = argparse.ArgumentParser(description="OpenAI ChatAPI çœŸå® API æµ‹è¯•")
    parser.add_argument('--api-key', help='API Keyï¼ˆä¸æ¨èï¼Œå»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰')
    parser.add_argument('--base-url', help='è‡ªå®šä¹‰ API åœ°å€')
    parser.add_argument('--include-expensive', action='store_true', 
                       help='åŒ…å«æ˜‚è´µçš„æµ‹è¯•ï¼ˆå¦‚å¤šæ¨¡æ€ï¼‰')
    parser.add_argument('--model', default='qwen3-8b', help='æµ‹è¯•ä½¿ç”¨çš„æ¨¡å‹')
    
    args = parser.parse_args()
    
    # è·å– API key
    import os
    api_key = args.api_key or os.getenv('OPENAI_API_KEY')
    
    if not api_key:
        print("âŒ é”™è¯¯: æœªæä¾› API Key")
        print("\nè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€æä¾› API Key:")
        print("  1. ç¯å¢ƒå˜é‡: export OPENAI_API_KEY='your-key'")
        print("  2. å‘½ä»¤è¡Œå‚æ•°: --api-key 'your-key'")
        return 1
    
    # åˆ›å»ºæµ‹è¯•é…ç½®
    test_config = TestConfig(api_key=api_key, base_url=args.base_url)
    test_config.test_model = args.model

    # å¦‚æœå‘½ä»¤è¡Œæœªä¼  base-urlï¼Œåˆ™å°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–
    if not test_config.base_url:
        import os
        env_base = os.getenv('OPENAI_API_BASE_URL')
        if env_base:
            test_config.base_url = env_base
    
    # è¿è¡Œæµ‹è¯•
    try:
        exit_code = asyncio.run(run_real_api_tests(
            test_config, 
            skip_expensive=not args.include_expensive
        ))
        return exit_code
    except KeyboardInterrupt:
        print("\n\næµ‹è¯•å·²å–æ¶ˆ")
        return 1
    except Exception as e:
        print(f"\n\næµ‹è¯•è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
