#!/usr/bin/env python3
"""
ç¤ºä¾‹ 3: å·¥å…·è°ƒç”¨ (Function Calling)
æ¼”ç¤ºå¦‚ä½•è®© AI è°ƒç”¨å·¥å…·å‡½æ•°ï¼ŒåŒ…æ‹¬éæµå¼å’Œæµå¼ä¸¤ç§æ¨¡å¼

åŠŸèƒ½ç‰¹æ€§:
- éæµå¼å·¥å…·è°ƒç”¨ï¼ˆchatï¼‰
- æµå¼å·¥å…·è°ƒç”¨ï¼ˆchat_streamï¼‰
- è‡ªå®šä¹‰å›è°ƒå‡½æ•°å¤„ç†å“åº”
- æ§åˆ¶ç»ˆç«¯è¾“å‡ºæ˜¾ç¤º
"""

# å¯ç¼–è¾‘ï¼šä¼˜å…ˆåœ¨è¿™é‡Œå¡«å†™ API å‚æ•°ï¼Œç•™ç©º (None) åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶
API_KEY = None  # åœ¨æ­¤å¡«å†™ä½ çš„ API Key
API_BASE_URL = None  # åœ¨æ­¤å¡«å†™ä½ çš„ API Base URL
MODEL = "qwen-plus"  # åœ¨æ­¤å¡«å†™ä½ çš„æ¨¡å‹åç§°

import asyncio
import os
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from chat_agent import ChatAgent
from model_config import ModelConfig
from runtime_config import RuntimeConfig
from tools.tool_loader import load_tools_for_agent

# å¡«å…… API å‚æ•°
if API_KEY is None:
    API_KEY = os.getenv("OPENAI_API_KEY")
if API_BASE_URL is None:
    API_BASE_URL = os.getenv("OPENAI_API_BASE_URL")

if API_KEY is None or API_BASE_URL is None or MODEL is None:
    try:
        cfg_path = Path(__file__).parent.parent / "config" / "default_model_config.yaml"
        if cfg_path.exists():
            cfg = ModelConfig.from_yaml(str(cfg_path))
            if API_KEY is None:
                API_KEY = cfg.api_key
            if API_BASE_URL is None:
                API_BASE_URL = cfg.api_base_url
            if MODEL == "qwen-plus":  # å¦‚æœæ˜¯é»˜è®¤å€¼ï¼Œä»é…ç½®åŠ è½½
                MODEL = cfg.model
    except Exception:
        pass


# ========== å›è°ƒå‡½æ•°ç¤ºä¾‹ ==========

def chunk_callback(chunk: str):
    """æ¯ä¸ªæµå¼chunkçš„å›è°ƒ"""
    # å¯ä»¥åœ¨è¿™é‡Œå¤„ç†æ¯ä¸ªchunkï¼Œä¾‹å¦‚ä¿å­˜åˆ°æ–‡ä»¶ã€å‘é€åˆ°å‰ç«¯ç­‰
    pass  # è¿™é‡Œæˆ‘ä»¬ä¸åšé¢å¤–å¤„ç†ï¼Œè®©é»˜è®¤çš„ç»ˆç«¯è¾“å‡ºå·¥ä½œ


def response_callback(response: str):
    """å®Œæ•´å“åº”çš„å›è°ƒï¼ˆéæµå¼ï¼‰"""
    # å¯ä»¥åœ¨è¿™é‡Œå¤„ç†å®Œæ•´å“åº”
    print(f"\n[å›è°ƒ] æ”¶åˆ°å®Œæ•´å“åº”ï¼Œé•¿åº¦: {len(response)} å­—ç¬¦")


async def main():
    print("=" * 70)
    print("ç¤ºä¾‹ 3: å·¥å…·è°ƒç”¨ï¼ˆéæµå¼ + æµå¼ï¼‰")
    print("=" * 70)
    print()

    # é…ç½®
    model_config = ModelConfig(
        api_key=API_KEY,
        api_base_url=API_BASE_URL,
        model=MODEL,
    )

    # RuntimeConfig é…ç½®è¯´æ˜ï¼š
    # - max_tool_iterations: æœ€å¤§å·¥å…·è°ƒç”¨è¿­ä»£æ¬¡æ•°
    # - tool_failure_policy: å·¥å…·å¤±è´¥å¤„ç†ç­–ç•¥ ('inject_message', 'raise', 'retry_once')
    # - stream_chunk_callback: æµå¼å“åº”æ¯ä¸ªchunkçš„å›è°ƒå‡½æ•°
    # - response_callback: éæµå¼å“åº”çš„å®Œæ•´å“åº”å›è°ƒå‡½æ•°
    # - display_stream_output: æ˜¯å¦åœ¨ç»ˆç«¯æ˜¾ç¤ºæµå¼è¾“å‡º
    runtime_config = RuntimeConfig(
        enable_logging=True,
        capture_token_usage=True,
        max_tool_iterations=10,
        tool_failure_policy='inject_message',
        stream_chunk_callback=chunk_callback,  # æµå¼chunkå›è°ƒ
        response_callback=response_callback,    # å®Œæ•´å“åº”å›è°ƒ
        display_stream_output=True,            # æ˜¾ç¤ºæµå¼è¾“å‡ºåˆ°ç»ˆç«¯
    )

    async with ChatAgent(model_config, runtime_config) as agent:

        # åŠ è½½å·¥å…·
        tools_dir = Path(__file__).parent.parent / "tools"
        tool_count = load_tools_for_agent(agent, tools_dir / "fake_tool.json")
        print(f"ğŸ“¦ å·²åŠ è½½ {tool_count} ä¸ªå·¥å…·\n")
        print("-" * 70 + "\n")

        # ==================== éæµå¼å·¥å…·è°ƒç”¨ ====================
        
        print("ã€ç¤ºä¾‹ 1: éæµå¼å·¥å…·è°ƒç”¨ - å¤©æ°”æŸ¥è¯¢ã€‘\n")
        print("ğŸ’¬ ç”¨æˆ·: åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\n")

        response = await agent.chat(
            "åŒ—äº¬çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
            auto_execute_tools=True
        )

        print(f"ğŸ¤– åŠ©æ‰‹: {response}\n")
        print("-" * 70 + "\n")

        # ==================== éæµå¼å¤šå·¥å…·è°ƒç”¨ ====================
        
        print("ã€ç¤ºä¾‹ 2: éæµå¼å¤šå·¥å…·è°ƒç”¨ - ç»„åˆä½¿ç”¨ã€‘\n")
        print("ğŸ’¬ ç”¨æˆ·: å¸®æˆ‘æœç´¢'äººå·¥æ™ºèƒ½'å¹¶è®¡ç®— 2023 + 2024\n")

        response = await agent.chat(
            "å¸®æˆ‘æœç´¢'äººå·¥æ™ºèƒ½'å¹¶è®¡ç®— 2023 + 2024",
            auto_execute_tools=True,
            max_tool_iterations=5
        )

        print(f"ğŸ¤– åŠ©æ‰‹: {response}\n")
        print("-" * 70 + "\n")

        # ==================== æµå¼å·¥å…·è°ƒç”¨ ====================
        
        print("ã€ç¤ºä¾‹ 3: æµå¼å·¥å…·è°ƒç”¨ - å¤©æ°”æŸ¥è¯¢ã€‘\n")
        print("ğŸ’¬ ç”¨æˆ·: æŸ¥è¯¢ä¸Šæµ·çš„å¤©æ°”\n")
        print("ğŸ¤– åŠ©æ‰‹: ", end='', flush=True)

        full_response = ""
        async for chunk in agent.chat_stream(
            "æŸ¥è¯¢ä¸Šæµ·çš„å¤©æ°”",
            auto_execute_tools=True,
            display_stream=True  # æ˜¾ç¤ºæµå¼è¾“å‡º
        ):
            full_response += chunk

        print()  # æ¢è¡Œ
        print("-" * 70 + "\n")

        # ==================== æµå¼å·¥å…·è°ƒç”¨ï¼ˆç¦ç”¨ç»ˆç«¯è¾“å‡ºï¼‰====================
        
        print("ã€ç¤ºä¾‹ 4: æµå¼å·¥å…·è°ƒç”¨ï¼ˆç¦ç”¨ç»ˆç«¯æ˜¾ç¤ºï¼‰ã€‘\n")
        print("ğŸ’¬ ç”¨æˆ·: æŸ¥è¯¢æ·±åœ³çš„å¤©æ°”\n")
        
        # ä¸´æ—¶å…³é—­ç»ˆç«¯æ˜¾ç¤º
        original_display = agent.runtime_config.display_stream_output
        agent.runtime_config.display_stream_output = False
        
        print("ğŸ¤– åŠ©æ‰‹: [æµå¼è¾“å‡ºå·²å…³é—­ï¼Œä»…é€šè¿‡å›è°ƒå¤„ç†]")
        
        chunks_received = []
        async for chunk in agent.chat_stream(
            "æŸ¥è¯¢æ·±åœ³çš„å¤©æ°”",
            auto_execute_tools=True,
            display_stream=False  # ä¸åœ¨ç»ˆç«¯æ˜¾ç¤º
        ):
            chunks_received.append(chunk)
            # è¿™é‡Œå¯ä»¥å°†chunkå‘é€åˆ°ä½ çš„å‰ç«¯ã€ä¿å­˜åˆ°æ–‡ä»¶ç­‰
        
        # æ¢å¤ç»ˆç«¯æ˜¾ç¤ºè®¾ç½®
        agent.runtime_config.display_stream_output = original_display
        
        full_response = "".join(chunks_received)
        print(f"\nâœ… é€šè¿‡å›è°ƒæ”¶åˆ° {len(chunks_received)} ä¸ªchunksï¼Œæ€»é•¿åº¦: {len(full_response)} å­—ç¬¦")
        print(f"ğŸ“ å“åº”å†…å®¹: {full_response}\n")
        print("-" * 70 + "\n")

        # ==================== è‡ªå®šä¹‰å›è°ƒç¤ºä¾‹ ====================
        
        print("ã€ç¤ºä¾‹ 5: ä½¿ç”¨è‡ªå®šä¹‰å›è°ƒå¤„ç†æµå¼å“åº”ã€‘\n")
        print("ğŸ’¬ ç”¨æˆ·: æœç´¢'æœºå™¨å­¦ä¹ '\n")
        
        # å®šä¹‰è‡ªå®šä¹‰å›è°ƒ
        collected_chunks = []
        
        def custom_chunk_handler(chunk: str):
            """è‡ªå®šä¹‰chunkå¤„ç†å™¨"""
            collected_chunks.append(chunk)
            # è¿™é‡Œå¯ä»¥å®ç°è‡ªå®šä¹‰é€»è¾‘ï¼š
            # - å®æ—¶å‘é€åˆ°WebSocket
            # - ä¿å­˜åˆ°æ•°æ®åº“
            # - æ›´æ–°UIè¿›åº¦æ¡ç­‰
        
        # ä¸´æ—¶æ›¿æ¢å›è°ƒ
        original_callback = agent.runtime_config.stream_chunk_callback
        agent.runtime_config.stream_chunk_callback = custom_chunk_handler
        
        print("ğŸ¤– åŠ©æ‰‹: ", end='', flush=True)
        
        async for chunk in agent.chat_stream(
            "æœç´¢'æœºå™¨å­¦ä¹ '",
            auto_execute_tools=True,
            display_stream=True
        ):
            pass  # chunkå·²é€šè¿‡å›è°ƒå¤„ç†
        
        print()
        print(f"âœ… è‡ªå®šä¹‰å›è°ƒæ”¶åˆ° {len(collected_chunks)} ä¸ªchunks")
        
        # æ¢å¤åŸå›è°ƒ
        agent.runtime_config.stream_chunk_callback = original_callback
        
        print("-" * 70 + "\n")

        # ==================== æ˜¾ç¤ºå¯¹è¯å†å² ====================
        
        print("ğŸ“‹ å¯¹è¯å†å²ï¼ˆæœ€è¿‘10æ¡ï¼‰:")
        for i, msg in enumerate(agent.messages[-10:], 1):
            if msg.role == "assistant" and getattr(msg, 'tool_calls', None):
                print(f"  {i}. [åŠ©æ‰‹] è°ƒç”¨å·¥å…·: {[tc.function.name for tc in msg.tool_calls]}")
            elif msg.role == "tool":
                result = msg.content if isinstance(msg.content, str) else str(msg.content)
                print(f"  {i}. [å·¥å…·] {result[:60]}...")
            else:
                role = {"user": "ç”¨æˆ·", "assistant": "åŠ©æ‰‹"}.get(msg.role, msg.role)
                content = msg.content if isinstance(msg.content, str) else "[å†…å®¹]"
                print(f"  {i}. [{role}] {content[:50]}...")

        # ==================== ç»Ÿè®¡ä¿¡æ¯ ====================
        
        stats = agent.get_stats()
        print("\n" + "=" * 70)
        print(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»è¯·æ±‚: {stats['total_requests']}")
        print(f"   æ€»Token: {stats['total_tokens']}")
        print(f"   å¹³å‡å»¶è¿Ÿ: {stats.get('average_latency', 0.0):.2f}s")
        print("=" * 70)

        # ==================== ä½¿ç”¨è¯´æ˜ ====================
        
        print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
        print("   1. éæµå¼è°ƒç”¨: ä½¿ç”¨ agent.chat()")
        print("   2. æµå¼è°ƒç”¨: ä½¿ç”¨ agent.chat_stream()")
        print("   3. å›è°ƒå‡½æ•°:")
        print("      - stream_chunk_callback: å¤„ç†æ¯ä¸ªæµå¼chunk")
        print("      - response_callback: å¤„ç†å®Œæ•´å“åº”ï¼ˆéæµå¼ï¼‰")
        print("   4. æ§åˆ¶ç»ˆç«¯è¾“å‡º:")
        print("      - display_stream_output=True/False (åœ¨runtime_configä¸­)")
        print("      - display_stream=True/False (åœ¨chat_streamå‚æ•°ä¸­)")
        print("   5. å·¥å…·ç›¸å…³:")
        print("      - auto_execute_tools=True: è‡ªåŠ¨æ‰§è¡Œå·¥å…·")
        print("      - max_tool_iterations: æ§åˆ¶æœ€å¤šå‡ è½®å·¥å…·è°ƒç”¨")
        print("      - tool_failure_policy: å·¥å…·å¤±è´¥å¤„ç†ç­–ç•¥")


if __name__ == "__main__":
    try:
        # æé†’ç”¨æˆ·è®¾ç½® API key
        if not os.getenv("OPENAI_API_KEY") and API_KEY is None:
            print("âš ï¸  Warning: API Key not configured")
            print("   Please set API_KEY in the file or OPENAI_API_KEY environment variable\n")
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ å·²å–æ¶ˆ")
    except Exception as e:
        print(f"\n\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
