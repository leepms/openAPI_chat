#!/usr/bin/env python3
"""
ç¤ºä¾‹ 4: é…ç½®ç®¡ç†ä¸æ—¥å¿—ç›‘æ§
æ¼”ç¤º ModelConfig å’Œ RuntimeConfig çš„å„ç§é…ç½®æ–¹å¼ï¼Œä»¥åŠæ—¥å¿—ã€HTTP æ•æ‰ã€ç»Ÿè®¡ç­‰åŠŸèƒ½
"""

API_KEY = None
API_BASE_URL = None
MODEL = "qwen-plus"

import asyncio
import os
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from chat_agent import ChatAgent
from model_config import ModelConfig
from runtime_config import RuntimeConfig

# å¡«å…… API å‚æ•°
if API_KEY is None:
    API_KEY = os.getenv("OPENAI_API_KEY")
if API_BASE_URL is None:
    API_BASE_URL = os.getenv("OPENAI_API_BASE_URL")

if API_KEY is None or API_BASE_URL is None:
    try:
        cfg_path = Path(__file__).parent.parent / "config" / "default_model_config.yaml"
        if cfg_path.exists():
            cfg = ModelConfig.from_yaml(str(cfg_path))
            if API_KEY is None:
                API_KEY = cfg.api_key
            if API_BASE_URL is None:
                API_BASE_URL = cfg.api_base_url
    except Exception:
        pass


async def main():
    print("=" * 70)
    print("ç¤ºä¾‹ 4: é…ç½®ç®¡ç†ä¸æ—¥å¿—ç›‘æ§")
    print("=" * 70)
    print()

    config_dir = Path(__file__).parent.parent / "config"

    # ==================== ç¤ºä¾‹ 1: YAML é…ç½®æ–‡ä»¶ ====================
    
    print("ã€ç¤ºä¾‹ 1: YAML é…ç½®æ–‡ä»¶ã€‘\n")
    
    try:
        model_config = ModelConfig.from_yaml(str(config_dir / "default_model_config.yaml"))
        runtime_config = RuntimeConfig.from_yaml(str(config_dir / "default_runtime_config.yaml"))
        
        print(f"âœ… å·²åŠ è½½é…ç½®:")
        print(f"   æ¨¡å‹: {model_config.model}")
        print(f"   æ¸©åº¦: {model_config.temperature}")
        print(f"   æ—¥å¿—çº§åˆ«: {runtime_config.log_level}\n")
        
    except Exception as e:
        print(f"âŒ YAML é…ç½®åŠ è½½å¤±è´¥: {e}\n")
    
    print("-" * 70 + "\n")

    # ==================== ç¤ºä¾‹ 2: HTTP æŠ¥æ–‡æ•æ‰ ====================
    
    print("ã€ç¤ºä¾‹ 2: HTTP æŠ¥æ–‡æ•æ‰ã€‘\n")
    
    model_config = ModelConfig(
        api_key=API_KEY,
        api_base_url=API_BASE_URL,
        model=MODEL,
    )
    
    runtime_config = RuntimeConfig(
        enable_logging=True,
        log_level="INFO",
        capture_http_traffic=True,      # ä¸»å¼€å…³
        log_http_requests=True,         # è®°å½•è¯·æ±‚
        log_http_responses=True,        # è®°å½•å“åº”
        save_http_traffic_to_file=True, # ä¿å­˜åˆ°æ–‡ä»¶
        http_traffic_file_path="logs/http_traffic.log",
    )
    
    print("âœ… HTTP æ•æ‰é…ç½®:")
    print("   capture_http_traffic: True")
    print("   log_http_requests: True")
    print("   log_http_responses: True")
    print("   ä¿å­˜è·¯å¾„: logs/http_traffic.log\n")
    
    async with ChatAgent(model_config, runtime_config) as agent:
        print("ğŸ’¬ å‘é€è¯·æ±‚: ä½ å¥½\n")
        response = await agent.chat("ä½ å¥½", add_to_history=False)
        print(f"ğŸ¤– å“åº”: {response[:30]}...\n")
        print("ğŸ“ HTTP è¯·æ±‚å’Œå“åº”å·²è®°å½•åˆ°æ—¥å¿—\n")
    
    print("-" * 70 + "\n")

    # ==================== ç¤ºä¾‹ 3: Token ä½¿ç”¨ç»Ÿè®¡ ====================
    
    print("ã€ç¤ºä¾‹ 3: Token ä½¿ç”¨ç»Ÿè®¡ã€‘\n")
    
    runtime_config = RuntimeConfig(
        enable_logging=True,
        capture_token_usage=True,
        save_token_usage_to_file=True,
        token_usage_file_path="logs/token_usage.log",
        capture_latency=True,
        save_latency_to_file=True,
        latency_file_path="logs/latency.log",
    )
    
    print("âœ… ç»Ÿè®¡é…ç½®:")
    print("   capture_token_usage: True")
    print("   capture_latency: True")
    print("   ä¿å­˜åˆ°æ–‡ä»¶: True\n")
    
    async with ChatAgent(model_config, runtime_config) as agent:
        print("ğŸ’¬ æµ‹è¯•ç»Ÿè®¡: åˆ—ä¸¾ä¸‰ä¸ªå›½å®¶\n")
        response = await agent.chat("åˆ—ä¸¾ä¸‰ä¸ªå›½å®¶", add_to_history=False)
        print(f"ğŸ¤– å“åº”: {response}\n")
        
        # æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
        stats = agent.stats
        print("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»è¯·æ±‚æ•°: {stats.total_requests}")
        print(f"   æ€» Token: {stats.total_tokens}")
        print(f"   æç¤º Token: {stats.prompt_tokens}")
        print(f"   å®Œæˆ Token: {stats.completion_tokens}")
        print(f"   å¹³å‡å»¶è¿Ÿ: {stats.get_average_latency():.2f}s")
        print(f"   é”™è¯¯æ•°: {stats.errors}\n")
    
    print("-" * 70 + "\n")

    # ==================== ç¤ºä¾‹ 4: è°ƒè¯•æ¨¡å¼ ====================
    
    print("ã€ç¤ºä¾‹ 4: è°ƒè¯•æ¨¡å¼ï¼ˆä¿å­˜è¯·æ±‚/å“åº”ï¼‰ã€‘\n")
    
    runtime_config = RuntimeConfig(
        enable_logging=True,
        log_level="DEBUG",
        enable_debug=True,
        debug_save_requests=True,
        debug_save_responses=True,
        debug_output_dir="debug",
    )
    
    print("âœ… è°ƒè¯•é…ç½®:")
    print("   enable_debug: True")
    print("   debug_save_requests: True")
    print("   debug_save_responses: True")
    print("   è¾“å‡ºç›®å½•: debug/\n")
    
    async with ChatAgent(model_config, runtime_config) as agent:
        print("ğŸ’¬ è°ƒè¯•è¯·æ±‚: 1+1ç­‰äºå‡ ï¼Ÿ\n")
        response = await agent.chat("1+1ç­‰äºå‡ ï¼Ÿ", add_to_history=False)
        print(f"ğŸ¤– å“åº”: {response}\n")
        print("ğŸ“ è¯·æ±‚å’Œå“åº”å·²ä¿å­˜åˆ° debug/ ç›®å½•\n")
    
    print("-" * 70 + "\n")

    # ==================== ç¤ºä¾‹ 5: å›è°ƒå‡½æ•°é…ç½® ====================
    
    print("ã€ç¤ºä¾‹ 5: å›è°ƒå‡½æ•°é…ç½®ã€‘\n")
    
    class ResponseMonitor:
        """ç›‘æ§å’Œåˆ†æå“åº”"""
        def __init__(self):
            self.responses = []
            self.chunks = []
        
        def on_response(self, response: str):
            """å¤„ç†å®Œæ•´å“åº”"""
            self.responses.append(response)
            print(f"   [å›è°ƒ] æ”¶åˆ°å“åº”ï¼Œé•¿åº¦: {len(response)} å­—ç¬¦")
        
        def on_chunk(self, chunk: str):
            """å¤„ç†æµå¼ chunk"""
            self.chunks.append(chunk)
    
    monitor = ResponseMonitor()
    
    runtime_config = RuntimeConfig(
        enable_logging=True,
        response_callback=monitor.on_response,
        stream_chunk_callback=monitor.on_chunk,
        display_stream_output=True,
    )
    
    print("âœ… å›è°ƒé…ç½®:")
    print("   response_callback: monitor.on_response")
    print("   stream_chunk_callback: monitor.on_chunk\n")
    
    async with ChatAgent(model_config, runtime_config) as agent:
        print("ğŸ’¬ éæµå¼è¯·æ±‚: ä½ å¥½\n")
        response = await agent.chat("ä½ å¥½", add_to_history=False)
        print(f"ğŸ¤– å“åº”: {response[:30]}...\n")
        
        print("ğŸ’¬ æµå¼è¯·æ±‚: æ•°åˆ° 3\n")
        print("ğŸ¤– æµå¼: ", end="", flush=True)
        async for chunk in agent.chat_stream("æ•°åˆ° 3", display_stream=True):
            pass
        print(f"\n   [å›è°ƒ] æ”¶åˆ° {len(monitor.chunks)} ä¸ª chunks\n")
    
    print("-" * 70 + "\n")

    # ==================== ç¤ºä¾‹ 6: æ··åˆé…ç½®ï¼ˆYAML + ä»£ç ï¼‰====================
    
    print("ã€ç¤ºä¾‹ 6: æ··åˆé…ç½®ï¼ˆæ¨èç”¨äºç”Ÿäº§ï¼‰ã€‘\n")
    
    try:
        # ä» YAML åŠ è½½åŸºç¡€é…ç½®
        model_config = ModelConfig.from_yaml(
            str(config_dir / "default_model_config.yaml")
        )
        runtime_config = RuntimeConfig.from_yaml(
            str(config_dir / "default_runtime_config.yaml")
        )
        
        # é€šè¿‡ä»£ç è¦†ç›–å…³é”®å‚æ•°
        model_config.temperature = 0.8
        runtime_config.log_level = "WARNING"
        runtime_config.display_stream_output = False
        runtime_config.capture_token_usage = True
        runtime_config.capture_http_traffic = False
        
        print("âœ… æ··åˆé…ç½®:")
        print(f"   åŸºç¡€: YAML æ–‡ä»¶")
        print(f"   è¦†ç›–æ¸©åº¦: {model_config.temperature}")
        print(f"   è¦†ç›–æ—¥å¿—çº§åˆ«: {runtime_config.log_level}")
        print(f"   å…³é—­ HTTP æ•æ‰ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰")
        print(f"   å…³é—­ç»ˆç«¯æ˜¾ç¤ºï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰\n")
        
    except Exception as e:
        print(f"âŒ æ··åˆé…ç½®å¤±è´¥: {e}\n")
    
    print("-" * 70 + "\n")


if __name__ == "__main__":
    try:
        if not os.getenv("OPENAI_API_KEY") and API_KEY is None:
            print("âš ï¸  Warning: API Key not configured\n")
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ å·²å–æ¶ˆ")
    except Exception as e:
        print(f"\n\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
