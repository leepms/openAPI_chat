"""
ARCHIVED: example_6_config_management.py

Configuration management examples are archived. Use the project's
`config/` folder and `ModelConfig` utilities directly.
"""

print("example_6_config_management.py archived. See config/default_model_config.yaml for examples.")

async def example_yaml_config():
    """ä½¿ç”¨ YAML é…ç½®æ–‡ä»¶"""
    
    print("ã€æ–¹å¼ 1: YAML é…ç½®æ–‡ä»¶ã€‘\n")
    
    config_dir = Path(__file__).parent.parent / "config"
    
    # ä» YAML åŠ è½½é…ç½®
    model_config = ModelConfig.from_yaml(config_dir / "default_model_config.yaml")
    runtime_config = RuntimeConfig.from_yaml(config_dir / "default_runtime_config.yaml")
    
    # å¯ä»¥è¦†ç›–éƒ¨åˆ†å‚æ•°
    model_config.temperature = 0.8
    
    print(f"âœ… å·²åŠ è½½é…ç½®:")
    print(f"   æ¨¡å‹: {model_config.model}")
    print(f"   æ¸©åº¦: {model_config.temperature}")
    print(f"   æ—¥å¿—çº§åˆ«: {runtime_config.log_level}\n")
    
    return model_config, runtime_config

async def example_code_config():
    """åœ¨ä»£ç ä¸­ç›´æ¥é…ç½®"""
    
    print("ã€æ–¹å¼ 2: ä»£ç é…ç½®ã€‘\n")
    
    model_config = ModelConfig(
        api_key="your-api-key-here",
        model="gpt-4o-mini",
        temperature=0.7,
        max_tokens=1000,
    )
    
    runtime_config = RuntimeConfig(
        enable_logging=True,
        log_level="INFO",
        capture_token_usage=True,
    )
    
    print(f"âœ… å·²åˆ›å»ºé…ç½®:")
    print(f"   æ¨¡å‹: {model_config.model}")
    print(f"   æ¸©åº¦: {model_config.temperature}\n")
    
    return model_config, runtime_config

async def example_env_config():
    """ä½¿ç”¨ç¯å¢ƒå˜é‡"""
    
    print("ã€æ–¹å¼ 3: ç¯å¢ƒå˜é‡ã€‘\n")
    
    import os
    
    # API key å¯ä»¥ä»ç¯å¢ƒå˜é‡è¯»å–
    model_config = ModelConfig(
        model="gpt-4o-mini",
        # api_key ä¼šè‡ªåŠ¨ä» OPENAI_API_KEY ç¯å¢ƒå˜é‡è¯»å–
    )
    
    print(f"âœ… é…ç½®è¯´æ˜:")
    print(f"   API Key: {'å·²è®¾ç½®' if os.getenv('OPENAI_API_KEY') else 'æœªè®¾ç½®ï¼ˆéœ€è¦è®¾ç½® OPENAI_API_KEYï¼‰'}")
    print(f"   æ¨¡å‹: {model_config.model}\n")
    
    return model_config, RuntimeConfig()

async def example_hybrid_config():
    """æ··åˆé…ç½®æ–¹å¼"""
    
    print("ã€æ–¹å¼ 4: æ··åˆé…ç½®ï¼ˆæ¨èï¼‰ã€‘\n")
    
    config_dir = Path(__file__).parent.parent / "config"
    
    # ä» YAML åŠ è½½åŸºç¡€é…ç½®
    model_config = ModelConfig.from_yaml(
        config_dir / "default_model_config.yaml",
        # é€šè¿‡å‚æ•°è¦†ç›–
        temperature=0.9,
        max_tokens=1500,
    )
    
    runtime_config = RuntimeConfig.from_yaml(
        config_dir / "default_runtime_config.yaml",
        log_level="DEBUG",  # è¦†ç›–æ—¥å¿—çº§åˆ«
    )
    
    print(f"âœ… æ··åˆé…ç½®:")
    print(f"   åŸºç¡€æ¥æº: YAML æ–‡ä»¶")
    print(f"   è¦†ç›–å‚æ•°: temperature=0.9, max_tokens=1500")
    print(f"   æœ€ç»ˆæ¸©åº¦: {model_config.temperature}\n")
    
    return model_config, runtime_config

API_KEY = "sk-0253dd96205d4d83b0b792e08dfaec06"  # e.g. "sk-..." æˆ– None
API_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"  # e.g. "https://api.openai.com/v1" æˆ– None
MODEL = "qwen3-32b"
async def main():
    print("=" * 60)
    print("ç¤ºä¾‹ 6: é…ç½®ç®¡ç†")
    print("=" * 60)
    print()
    
    # æ¼”ç¤ºä¸åŒçš„é…ç½®æ–¹å¼
    configs = []
    
    try:
        configs.append(await example_yaml_config())
        print("-" * 60 + "\n")
    except Exception as e:
        print(f"YAML é…ç½®ç¤ºä¾‹å¤±è´¥: {e}\n")
    try:
        configs.append(await example_hybrid_config())
        print("-" * 60 + "\n")
    except Exception as e:
        print(f"æ··åˆé…ç½®ç¤ºä¾‹å¤±è´¥: {e}\n")
    
    # ä½¿ç”¨å…¶ä¸­ä¸€ä¸ªé…ç½®è¿›è¡Œå®é™…å¯¹è¯
    if configs:
        model_config, runtime_config = configs[1]  # ä½¿ç”¨ä»£ç é…ç½®
        
        print("ã€é…ç½®æµ‹è¯•ã€‘\n")
        print("ğŸ’¬ ç”¨æˆ·: ä½ å¥½\n")
        
        # æ³¨æ„ï¼šéœ€è¦æœ‰æ•ˆçš„ API key æ‰èƒ½è¿è¡Œ
        """
        async with ChatAgent(model_config, runtime_config) as agent:
            response = await agent.chat("ä½ å¥½")
            print(f"ğŸ¤– åŠ©æ‰‹: {response}\n")
        """
        
        print("âš ï¸  é…ç½®å·²å‡†å¤‡å¥½ï¼Œå–æ¶ˆæ³¨é‡Šä¸Šæ–¹ä»£ç å¹¶è®¾ç½® API key å³å¯è¿è¡Œ\n")
    
    print("=" * 60)
    print("ğŸ“ é…ç½®æœ€ä½³å®è·µ:")
    print("  1. å¼€å‘ç¯å¢ƒ: ä½¿ç”¨ YAML + ç¯å¢ƒå˜é‡")
    print("  2. ç”Ÿäº§ç¯å¢ƒ: ä½¿ç”¨ç¯å¢ƒå˜é‡ + ä»£ç è¦†ç›–")
    print("  3. æµ‹è¯•ç¯å¢ƒ: ç›´æ¥ä»£ç é…ç½®")
    print("  4. æ•æ„Ÿä¿¡æ¯: å§‹ç»ˆä½¿ç”¨ç¯å¢ƒå˜é‡")
    print("=" * 60)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nå·²å–æ¶ˆ")
    except Exception as e:
        print(f"\né”™è¯¯: {e}")

import asyncio
import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent))

from openai_chatapi import ChatAgent, ModelConfig, RuntimeConfig


async def example_yaml_config():
    """ä½¿ç”¨ YAML é…ç½®æ–‡ä»¶"""
    
    print("ã€æ–¹å¼ 1: YAML é…ç½®æ–‡ä»¶ã€‘\n")
    
    config_dir = Path(__file__).parent.parent / "config"
    
    # ä» YAML åŠ è½½é…ç½®
    model_config = ModelConfig.from_yaml(config_dir / "default_model_config.yaml")
    runtime_config = RuntimeConfig.from_yaml(config_dir / "default_runtime_config.yaml")
    
    # å¯ä»¥è¦†ç›–éƒ¨åˆ†å‚æ•°
    model_config.temperature = 0.8
    
    print(f"âœ… å·²åŠ è½½é…ç½®:")
    print(f"   æ¨¡å‹: {model_config.model}")
    print(f"   æ¸©åº¦: {model_config.temperature}")
    print(f"   æ—¥å¿—çº§åˆ«: {runtime_config.log_level}\n")
    
    return model_config, runtime_config


async def example_code_config():
    """åœ¨ä»£ç ä¸­ç›´æ¥é…ç½®"""
    
    print("ã€æ–¹å¼ 2: ä»£ç é…ç½®ã€‘\n")
    
    model_config = ModelConfig(
        api_key="your-api-key-here",
        model="gpt-4o-mini",
        temperature=0.7,
        max_tokens=1000,
    )
    
    runtime_config = RuntimeConfig(
        enable_logging=True,
        log_level="INFO",
        capture_token_usage=True,
    )
    
    print(f"âœ… å·²åˆ›å»ºé…ç½®:")
    print(f"   æ¨¡å‹: {model_config.model}")
    print(f"   æ¸©åº¦: {model_config.temperature}\n")
    
    return model_config, runtime_config


async def example_env_config():
    """ä½¿ç”¨ç¯å¢ƒå˜é‡"""
    
    print("ã€æ–¹å¼ 3: ç¯å¢ƒå˜é‡ã€‘\n")
    
    import os
    
    # API key å¯ä»¥ä»ç¯å¢ƒå˜é‡è¯»å–
    model_config = ModelConfig(
        model="gpt-4o-mini",
        # api_key ä¼šè‡ªåŠ¨ä» OPENAI_API_KEY ç¯å¢ƒå˜é‡è¯»å–
    )
    
    print(f"âœ… é…ç½®è¯´æ˜:")
    print(f"   API Key: {'å·²è®¾ç½®' if os.getenv('OPENAI_API_KEY') else 'æœªè®¾ç½®ï¼ˆéœ€è¦è®¾ç½® OPENAI_API_KEYï¼‰'}")
    print(f"   æ¨¡å‹: {model_config.model}\n")
    
    return model_config, RuntimeConfig()


async def example_hybrid_config():
    """æ··åˆé…ç½®æ–¹å¼"""
    
    print("ã€æ–¹å¼ 4: æ··åˆé…ç½®ï¼ˆæ¨èï¼‰ã€‘\n")
    
    config_dir = Path(__file__).parent.parent / "config"
    
    # ä» YAML åŠ è½½åŸºç¡€é…ç½®
    model_config = ModelConfig.from_yaml(
        config_dir / "default_model_config.yaml",
        # é€šè¿‡å‚æ•°è¦†ç›–
        temperature=0.9,
        max_tokens=1500,
    )
    
    runtime_config = RuntimeConfig.from_yaml(
        config_dir / "default_runtime_config.yaml",
        log_level="DEBUG",  # è¦†ç›–æ—¥å¿—çº§åˆ«
    )
    
    print(f"âœ… æ··åˆé…ç½®:")
    print(f"   åŸºç¡€æ¥æº: YAML æ–‡ä»¶")
    print(f"   è¦†ç›–å‚æ•°: temperature=0.9, max_tokens=1500")
    print(f"   æœ€ç»ˆæ¸©åº¦: {model_config.temperature}\n")
    
    return model_config, runtime_config


# å¯ç¼–è¾‘ï¼šä¼˜å…ˆåœ¨è¿™é‡Œå¡«å†™ API å‚æ•°ï¼Œç•™ç©º (None) åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶
API_KEY = "sk-0253dd96205d4d83b0b792e08dfaec06"  # e.g. "sk-..." æˆ– None
API_BASE_URL = "https://dashscope.aliyuncs.com/compatible-mode/v1"  # e.g. "https://api.openai.com/v1" æˆ– None
MODEL = "qwen3-32b"
async def main():
    print("=" * 60)
    print("ç¤ºä¾‹ 6: é…ç½®ç®¡ç†")
    print("=" * 60)
    print()
    
    # æ¼”ç¤ºä¸åŒçš„é…ç½®æ–¹å¼
    configs = []
    
    try:
        configs.append(await example_yaml_config())
        print("-" * 60 + "\n")
    except Exception as e:
        print(f"YAML é…ç½®ç¤ºä¾‹å¤±è´¥: {e}\n")
    try:
        configs.append(await example_hybrid_config())
        print("-" * 60 + "\n")
    except Exception as e:
        print(f"æ··åˆé…ç½®ç¤ºä¾‹å¤±è´¥: {e}\n")
    
    # ä½¿ç”¨å…¶ä¸­ä¸€ä¸ªé…ç½®è¿›è¡Œå®é™…å¯¹è¯
    if configs:
        model_config, runtime_config = configs[1]  # ä½¿ç”¨ä»£ç é…ç½®
        
        print("ã€é…ç½®æµ‹è¯•ã€‘\n")
        print("ğŸ’¬ ç”¨æˆ·: ä½ å¥½\n")
        
        # æ³¨æ„ï¼šéœ€è¦æœ‰æ•ˆçš„ API key æ‰èƒ½è¿è¡Œ
        """
        async with ChatAgent(model_config, runtime_config) as agent:
            response = await agent.chat("ä½ å¥½")
            print(f"ğŸ¤– åŠ©æ‰‹: {response}\n")
        """
        
        print("âš ï¸  é…ç½®å·²å‡†å¤‡å¥½ï¼Œå–æ¶ˆæ³¨é‡Šä¸Šæ–¹ä»£ç å¹¶è®¾ç½® API key å³å¯è¿è¡Œ\n")
    
    print("=" * 60)
    print("ğŸ“ é…ç½®æœ€ä½³å®è·µ:")
    print("  1. å¼€å‘ç¯å¢ƒ: ä½¿ç”¨ YAML + ç¯å¢ƒå˜é‡")
    print("  2. ç”Ÿäº§ç¯å¢ƒ: ä½¿ç”¨ç¯å¢ƒå˜é‡ + ä»£ç è¦†ç›–")
    print("  3. æµ‹è¯•ç¯å¢ƒ: ç›´æ¥ä»£ç é…ç½®")
    print("  4. æ•æ„Ÿä¿¡æ¯: å§‹ç»ˆä½¿ç”¨ç¯å¢ƒå˜é‡")
    print("=" * 60)


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nå·²å–æ¶ˆ")
    except Exception as e:
        print(f"\né”™è¯¯: {e}")
