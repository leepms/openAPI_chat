# OpenAI Chat API Client - æ¨¡å—å®Œå–„æ›´æ–°æ–‡æ¡£

## æ›´æ–°æ—¶é—´ï¼š2025-12-25

---

## ğŸ“ 1. ç›®å½•ç»“æ„ä¼˜åŒ–

### å˜æ›´å†…å®¹

**æ–‡ä»¶é‡æ–°ç»„ç»‡ï¼š**
```
openai_chatapi/
â”œâ”€â”€ docs/                    # ğŸ“š æ–‡æ¡£ç›®å½•ï¼ˆæ–°ï¼‰
â”‚   â”œâ”€â”€ README.md           # ä¸»æ–‡æ¡£
â”‚   â”œâ”€â”€ CHANGELOG_v0.3.md   # ç‰ˆæœ¬æ›´æ–°æ—¥å¿—
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ test/                    # ğŸ§ª æµ‹è¯•ç›®å½•ï¼ˆæ–°ï¼‰
â”‚   â”œâ”€â”€ test_chat_agent.py  # æµ‹è¯•å¥—ä»¶
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ examples/                # ğŸ’¡ ç¤ºä¾‹ç›®å½•ï¼ˆæ–°ï¼‰
â”‚   â”œâ”€â”€ example.py          # åŸºç¡€ç¤ºä¾‹
â”‚   â”œâ”€â”€ examples_complete.py # å®Œæ•´ç¤ºä¾‹
â”‚   â”œâ”€â”€ examples_v0.3.py    # v0.3 æ–°åŠŸèƒ½
â”‚   â”œâ”€â”€ manual_test.py      # æ‰‹åŠ¨æµ‹è¯•
â”‚   â”œâ”€â”€ config_templates_demo.py  # é…ç½®æ¨¡æ¿æ¼”ç¤ºï¼ˆæ–°ï¼‰
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ tools/                   # ğŸ”§ å·¥å…·ç›®å½•
â”‚   â””â”€â”€ (é¢„ç•™)
â”œâ”€â”€ config/                  # âš™ï¸ é…ç½®ç›®å½•
â”‚   â””â”€â”€ (é¢„ç•™)
â”œâ”€â”€ data/                    # ğŸ“Š æ•°æ®ç›®å½•
â”‚   â””â”€â”€ (é¢„ç•™)
â”œâ”€â”€ logs/                    # ğŸ“ æ—¥å¿—ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â”‚   â”œâ”€â”€ openai_chatapi.log
â”‚   â”œâ”€â”€ http_traffic.log
â”‚   â”œâ”€â”€ token_usage.log
â”‚   â””â”€â”€ latency.log
â””â”€â”€ debug/                   # ğŸ› è°ƒè¯•ç›®å½•ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
    â”œâ”€â”€ request_*.json
    â””â”€â”€ response_*.json
```

### ä¼˜åŠ¿

- âœ… æ¸…æ™°çš„æ¨¡å—åˆ’åˆ†
- âœ… æ˜“äºç»´æŠ¤å’Œæ‰©å±•
- âœ… ç¬¦åˆPythoné¡¹ç›®æœ€ä½³å®è·µ
- âœ… æ‰€æœ‰å­ç›®å½•éƒ½æœ‰ `__init__.py`

---

## âš™ï¸ 2. é…ç½®æ¨¡æ¿ç³»ç»Ÿ

### æ–°å¢æ–‡ä»¶

- `config_templates.py` - é…ç½®æ¨¡æ¿å®šä¹‰
- `examples/config_templates_demo.py` - ä½¿ç”¨ç¤ºä¾‹

### æ ¸å¿ƒåŠŸèƒ½

#### 2.1 ModelConfig æ¨¡æ¿

**6ç§é¢„å®šä¹‰æ¨¡æ¿ï¼š**

1. **default** - é»˜è®¤é…ç½®
   ```python
   ModelConfigTemplate.default()
   ```

2. **creative** - åˆ›æ„ä»»åŠ¡ï¼ˆé«˜temperatureï¼‰
   ```python
   ModelConfigTemplate.creative()
   # temperature=0.9, top_p=0.95, frequency_penalty=0.5
   ```

3. **precise** - ç²¾ç¡®ä»»åŠ¡ï¼ˆä½temperature + seedï¼‰
   ```python
   ModelConfigTemplate.precise()
   # temperature=0.1, seed=42
   ```

4. **reasoning** - æ¨ç†æ¨¡å‹ï¼ˆo1ç³»åˆ—ï¼‰
   ```python
   ModelConfigTemplate.reasoning()
   # model="o1-preview", reasoning_effort="high"
   ```

5. **local** - æœ¬åœ°æ¨¡å‹ï¼ˆOllamaç­‰ï¼‰
   ```python
   ModelConfigTemplate.local()
   # api_base_url="http://localhost:11434/v1"
   ```

6. **cost_effective** - ç»æµå‹ï¼ˆGPT-3.5ï¼‰
   ```python
   ModelConfigTemplate.cost_effective()
   # model="gpt-3.5-turbo", max_tokens=500
   ```

#### 2.2 RuntimeConfig æ¨¡æ¿

**6ç§é¢„å®šä¹‰æ¨¡æ¿ï¼š**

1. **default** - é»˜è®¤è¿è¡Œé…ç½®
2. **production** - ç”Ÿäº§ç¯å¢ƒï¼ˆæœ€å°‘æ—¥å¿—ï¼‰
3. **development** - å¼€å‘ç¯å¢ƒï¼ˆå®Œæ•´æ—¥å¿—ï¼‰
4. **testing** - æµ‹è¯•ç¯å¢ƒï¼ˆæœ€å°æ—¥å¿—ï¼‰
5. **monitoring** - ç›‘æ§æ¨¡å¼ï¼ˆå…¨è¿½è¸ªï¼‰
6. **minimal** - æœ€å°æ¨¡å¼ï¼ˆå‡ ä¹æ— æ—¥å¿—ï¼‰

### ä½¿ç”¨æ–¹å¼

#### æ–¹å¼1ï¼šç›´æ¥ä½¿ç”¨æ¨¡æ¿

```python
from openai_chatapi import ModelConfigTemplate, RuntimeConfigTemplate

model_config = ModelConfigTemplate.creative()
runtime_config = RuntimeConfigTemplate.development()
```

#### æ–¹å¼2ï¼šæ¨¡æ¿ + è¦†ç›–ï¼ˆæ¨èï¼‰

```python
from openai_chatapi import create_model_config, create_runtime_config

# ä½¿ç”¨æ¨¡æ¿å¹¶è¦†ç›–ç‰¹å®šå­—æ®µ
model_config = create_model_config(
    "creative",
    api_key="sk-xxx",
    max_tokens=2000,
)

runtime_config = create_runtime_config(
    "production",
    timeout=120,
    capture_http_traffic=True,
)
```

#### æ–¹å¼3ï¼šåŠ¨æ€æ›´æ–°

```python
runtime_config = RuntimeConfigTemplate.default()

# è¿è¡Œæ—¶æ›´æ–°é…ç½®
runtime_config.update(
    log_level="DEBUG",
    enable_debug=True,
)
```

### ä¼˜åŠ¿

- âœ… **ä»£ç å‡å°‘70%** - æ— éœ€å®šä¹‰æ‰€æœ‰å­—æ®µ
- âœ… **æ„å›¾æ¸…æ™°** - æ¨¡æ¿åç§°å³è¯´æ˜ç”¨é€”
- âœ… **å‡å°‘é”™è¯¯** - é¢„è®¾å€¼å·²éªŒè¯
- âœ… **æ˜“äºç»´æŠ¤** - é›†ä¸­ç®¡ç†é…ç½®

---

## ğŸ“Š 3. ç»†åŒ–çš„æ—¥å¿—é…ç½®

### æ–°å¢é…ç½®å‚æ•°

```python
@dataclass
class RuntimeConfig:
    # ==================== åŸºç¡€æ—¥å¿— ====================
    enable_logging: bool = True
    log_level: str = "INFO"
    
    # ==================== æ–‡ä»¶æ—¥å¿— ====================
    save_logs_to_file: bool = False          # ä¿å­˜åˆ°æ–‡ä»¶
    log_file_path: str = "logs/openai_chatapi.log"
    log_file_max_bytes: int = 10 * 1024 * 1024  # 10MB
    log_file_backup_count: int = 5           # 5ä¸ªå¤‡ä»½
    
    # ==================== HTTPæµé‡æ•è· ====================
    capture_http_traffic: bool = False        # ä¸»å¼€å…³
    log_http_requests: bool = False          # è®°å½•è¯·æ±‚
    log_http_responses: bool = False         # è®°å½•å“åº”
    save_http_traffic_to_file: bool = False  # ä¿å­˜åˆ°æ–‡ä»¶
    http_traffic_file_path: str = "logs/http_traffic.log"
    
    # ==================== Tokenç»Ÿè®¡ ====================
    capture_token_usage: bool = True          # è¿½è¸ªToken
    save_token_usage_to_file: bool = False   # ä¿å­˜åˆ°æ–‡ä»¶
    token_usage_file_path: str = "logs/token_usage.log"
    
    # ==================== å»¶è¿Ÿè¿½è¸ª ====================
    capture_latency: bool = True              # è¿½è¸ªå»¶è¿Ÿ
    save_latency_to_file: bool = False       # ä¿å­˜åˆ°æ–‡ä»¶
    latency_file_path: str = "logs/latency.log"
    
    # ==================== è°ƒè¯•æ¨¡å¼ ====================
    enable_debug: bool = False
    debug_save_requests: bool = False         # ä¿å­˜è¯·æ±‚JSON
    debug_save_responses: bool = False        # ä¿å­˜å“åº”JSON
    debug_output_dir: str = "debug"
```

### ç‹¬ç«‹å¼€å…³è®¾è®¡

**åŠŸèƒ½1ï¼šè·å–HTTPæŠ¥æ–‡**
```python
runtime_config = RuntimeConfig(
    capture_http_traffic=True,    # å¯ç”¨HTTPæ•è·
    log_http_requests=True,        # åœ¨æ—¥å¿—ä¸­æ˜¾ç¤ºè¯·æ±‚
    log_http_responses=True,       # åœ¨æ—¥å¿—ä¸­æ˜¾ç¤ºå“åº”
    save_http_traffic_to_file=True,  # ä¿å­˜åˆ°æ–‡ä»¶
)
```

**åŠŸèƒ½2ï¼šè¿½è¸ªTokenä½¿ç”¨**
```python
runtime_config = RuntimeConfig(
    capture_token_usage=True,       # å¯ç”¨Tokenç»Ÿè®¡
    save_token_usage_to_file=True,  # ä¿å­˜ç»Ÿè®¡åˆ°æ–‡ä»¶
)

# è·å–ç»Ÿè®¡
stats = agent.get_stats()
# ä¿å­˜ç»Ÿè®¡
agent.save_stats()
```

**åŠŸèƒ½3ï¼šä¿å­˜è°ƒè¯•æ•°æ®**
```python
runtime_config = RuntimeConfig(
    enable_debug=True,
    debug_save_requests=True,       # ä¿å­˜æ¯ä¸ªè¯·æ±‚åˆ°JSON
    debug_save_responses=True,      # ä¿å­˜æ¯ä¸ªå“åº”åˆ°JSON
    debug_output_dir="debug",
)

# æ¯ä¸ªè¯·æ±‚ä¼šç”Ÿæˆï¼š
# debug/request_20251225_143052_123456.json
# debug/response_20251225_143053_789012.json
```

**åŠŸèƒ½4ï¼šä¿å­˜æœ¬åœ°æ—¥å¿—**
```python
runtime_config = RuntimeConfig(
    save_logs_to_file=True,
    log_file_path="logs/my_app.log",
    log_file_max_bytes=50 * 1024 * 1024,  # 50MB
    log_file_backup_count=10,              # 10ä¸ªå¤‡ä»½
)
```

### è‡ªåŠ¨ç›®å½•åˆ›å»º

æ‰€æœ‰æ—¥å¿—å’Œè°ƒè¯•ç›®å½•ä¼šè‡ªåŠ¨åˆ›å»ºï¼Œæ— éœ€æ‰‹åŠ¨åˆ›å»ºã€‚

---

## ğŸ”§ 4. æ–°å¢åŠŸèƒ½

### 4.1 UsageStats å¢å¼º

```python
# ä¿å­˜ç»Ÿè®¡åˆ°æ–‡ä»¶
agent.save_stats("logs/stats.log")

# æˆ–ä½¿ç”¨é…ç½®çš„è·¯å¾„
runtime_config = RuntimeConfig(
    capture_token_usage=True,
    save_token_usage_to_file=True,
)
agent.save_stats()  # è‡ªåŠ¨ä½¿ç”¨é…ç½®çš„è·¯å¾„
```

### 4.2 RuntimeConfig åŠ¨æ€æ›´æ–°

```python
# åˆ›å»ºé…ç½®
runtime_config = RuntimeConfig()

# è¿è¡Œæ—¶æ›´æ–°
runtime_config.update(
    log_level="DEBUG",
    enable_debug=True,
    capture_http_traffic=True,
)

# æ—¥å¿—é…ç½®ä¼šè‡ªåŠ¨é‡æ–°åˆå§‹åŒ–
```

### 4.3 é…ç½®å¯¼å‡º

```python
# å¯¼å‡ºé…ç½®ä¸ºå­—å…¸
config_dict = runtime_config.to_dict()

# å¯ç”¨äºåºåˆ—åŒ–ã€æ—¥å¿—è®°å½•ç­‰
import json
print(json.dumps(config_dict, indent=2))
```

---

## ğŸ“š 5. æ–‡æ¡£æ›´æ–°

### å·²æ›´æ–°æ–‡ä»¶

1. **docs/README.md** - å®Œæ•´æ–‡æ¡£ï¼ŒåŒ…å«é…ç½®æ¨¡æ¿ç« èŠ‚
2. **docs/CHANGELOG_v0.3.md** - ç‰ˆæœ¬æ›´æ–°æ—¥å¿—
3. **æœ¬æ–‡æ¡£** - æ¨¡å—å®Œå–„æ›´æ–°è¯´æ˜

### æ–°å¢ç¤ºä¾‹

1. **examples/config_templates_demo.py** - é…ç½®æ¨¡æ¿å®Œæ•´æ¼”ç¤º
   - 7ä¸ªç¤ºä¾‹è¦†ç›–æ‰€æœ‰ä½¿ç”¨åœºæ™¯
   - å¯¹æ¯”ä¼ ç»Ÿæ–¹å¼ vs æ¨¡æ¿æ–¹å¼

---

## ğŸš€ 6. è¿ç§»æŒ‡å—

### ä»æ—§ç‰ˆæœ¬å‡çº§

**æ— éœ€ä¿®æ”¹ä»£ç ï¼** æ‰€æœ‰æ—§ä»£ç å®Œå…¨å…¼å®¹ã€‚

#### å¯é€‰ï¼šä½¿ç”¨æ–°åŠŸèƒ½

**ä¹‹å‰ï¼š**
```python
from openai_chatapi import ChatAgent, ChatConfig

config = ChatConfig(
    api_base_url="https://api.openai.com/v1",
    api_key="sk-xxx",
    model="gpt-4o",
    temperature=0.9,
    top_p=0.95,
    # ... 10+ è¡Œé…ç½®
)

agent = ChatAgent(config)
```

**ç°åœ¨ï¼ˆæ¨èï¼‰ï¼š**
```python
from openai_chatapi import ChatAgent, create_model_config, create_runtime_config

model_config = create_model_config("creative", api_key="sk-xxx")
runtime_config = create_runtime_config("production")

agent = ChatAgent(model_config, runtime_config)
```

### ä½¿ç”¨ç»†åŒ–çš„æ—¥å¿—åŠŸèƒ½

**åœºæ™¯1ï¼šå¼€å‘è°ƒè¯•**
```python
runtime_config = create_runtime_config(
    "development",
    save_logs_to_file=True,
    debug_save_requests=True,
    debug_save_responses=True,
)
```

**åœºæ™¯2ï¼šç”Ÿäº§ç›‘æ§**
```python
runtime_config = create_runtime_config(
    "production",
    capture_token_usage=True,
    save_token_usage_to_file=True,
    capture_http_traffic=False,  # ç”Ÿäº§ç¯å¢ƒä¸è®°å½•HTTP
)
```

**åœºæ™¯3ï¼šé—®é¢˜åˆ†æ**
```python
runtime_config = create_runtime_config(
    "monitoring",
    capture_http_traffic=True,
    save_http_traffic_to_file=True,
    save_logs_to_file=True,
)
```

---

## ğŸ“Š 7. åŠŸèƒ½å¯¹æ¯”

| åŠŸèƒ½ | v0.2.0 | v0.3.0 (ä¹‹å‰) | v0.3.0 (ç°åœ¨) |
|------|--------|--------------|--------------|
| é…ç½®æ¨¡æ¿ | âŒ | âŒ | âœ… 6+6 æ¨¡æ¿ |
| é…ç½®è¦†ç›– | âŒ | âŒ | âœ… æ”¯æŒ |
| åŠ¨æ€æ›´æ–° | âŒ | âŒ | âœ… æ”¯æŒ |
| æ—¥å¿—åˆ†ç±» | åŸºç¡€ | éƒ¨åˆ† | âœ… å®Œå…¨åˆ†ç¦» |
| HTTPæ•è· | âŒ | æ··åˆ | âœ… ç‹¬ç«‹å¼€å…³ |
| Tokenè¿½è¸ª | âŒ | âœ… | âœ… å¯ä¿å­˜æ–‡ä»¶ |
| è°ƒè¯•æ¨¡å¼ | âŒ | éƒ¨åˆ† | âœ… å®Œæ•´æ”¯æŒ |
| ç›®å½•ç»„ç»‡ | æ··ä¹± | æ··ä¹± | âœ… æ¸…æ™°ç»“æ„ |
| æ–‡ä»¶ä¿å­˜ | âŒ | âŒ | âœ… è‡ªåŠ¨è½®è½¬ |

---

## ğŸ¯ 8. æœ€ä½³å®è·µ

### 8.1 å¼€å‘ç¯å¢ƒ

```python
from openai_chatapi import create_model_config, create_runtime_config, ChatAgent

# æœ¬åœ°æ¨¡å‹ + å®Œæ•´è°ƒè¯•
model_config = create_model_config(
    "local",
    api_base_url="http://localhost:11434/v1",
    model="qwen2.5:7b",
)

runtime_config = create_runtime_config(
    "development",
    debug_save_requests=True,
    debug_save_responses=True,
)

async with ChatAgent(model_config, runtime_config) as agent:
    response = await agent.chat("test")
```

### 8.2 ç”Ÿäº§ç¯å¢ƒ

```python
# äº‘ç«¯æ¨¡å‹ + æœ€å°æ—¥å¿— + Tokenè¿½è¸ª
model_config = create_model_config(
    "default",
    api_key=os.getenv("OPENAI_API_KEY"),
)

runtime_config = create_runtime_config(
    "production",
    capture_token_usage=True,
    save_token_usage_to_file=True,
)

async with ChatAgent(model_config, runtime_config) as agent:
    response = await agent.chat(user_input)
    
    # å®šæœŸä¿å­˜ç»Ÿè®¡
    agent.save_stats()
```

### 8.3 é—®é¢˜æ’æŸ¥

```python
# å®Œæ•´ç›‘æ§æ¨¡å¼
runtime_config = create_runtime_config(
    "monitoring",
    capture_http_traffic=True,
    save_http_traffic_to_file=True,
    debug_save_requests=True,
    debug_save_responses=True,
)

# æ‰€æœ‰æ•°æ®éƒ½ä¼šè¢«è®°å½•ï¼Œä¾¿äºåç»­åˆ†æ
```

---

## ğŸ“ 9. æ³¨æ„äº‹é¡¹

1. **æ—¥å¿—æ–‡ä»¶å¤§å°**ï¼šé»˜è®¤10MBè‡ªåŠ¨è½®è½¬ï¼Œå¯è°ƒæ•´ `log_file_max_bytes`
2. **è°ƒè¯•æ–‡ä»¶æ¸…ç†**ï¼šdebugç›®å½•ä¼šç§¯ç´¯JSONæ–‡ä»¶ï¼Œéœ€å®šæœŸæ¸…ç†
3. **æ€§èƒ½å½±å“**ï¼š
   - `capture_http_traffic` æœ‰è½»å¾®æ€§èƒ½å½±å“
   - `debug_save_*` ä¼šäº§ç”Ÿå¤§é‡I/Oï¼Œä»…è°ƒè¯•æ—¶ä½¿ç”¨
4. **è·¯å¾„é—®é¢˜**ï¼šæ‰€æœ‰è·¯å¾„éƒ½æ˜¯ç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•ï¼Œå»ºè®®ä½¿ç”¨ç»å¯¹è·¯å¾„

---

## ğŸ‰ 10. æ€»ç»“

### ä¸»è¦æ”¹è¿›

1. âœ… **ç›®å½•ç»“æ„æ¸…æ™°** - docs, test, examples åˆ†ç¦»
2. âœ… **é…ç½®æ¨¡æ¿ç³»ç»Ÿ** - 12ä¸ªé¢„å®šä¹‰æ¨¡æ¿
3. âœ… **ç»†åŒ–æ—¥å¿—æ§åˆ¶** - ç‹¬ç«‹å¼€å…³ï¼ŒæŒ‰éœ€å¼€å¯
4. âœ… **å®Œå–„æ–‡æ¡£** - ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µ
5. âœ… **å‘åå…¼å®¹** - æ—§ä»£ç æ— éœ€ä¿®æ”¹

### ä½¿ç”¨å»ºè®®

- ğŸš€ æ–°é¡¹ç›®ï¼šç›´æ¥ä½¿ç”¨é…ç½®æ¨¡æ¿
- ğŸ”§ æ—§é¡¹ç›®ï¼šå¯é€‰å‡çº§ï¼Œæ— ç ´åæ€§å˜æ›´
- ğŸ“Š ç›‘æ§éœ€æ±‚ï¼šä½¿ç”¨ monitoring æ¨¡æ¿
- ğŸ› è°ƒè¯•éœ€æ±‚ï¼šä½¿ç”¨ development æ¨¡æ¿

### å¿«é€Ÿå¼€å§‹

```python
from openai_chatapi import ChatAgent, create_model_config, create_runtime_config

# ä¸€è¡Œä»£ç æå®šé…ç½®ï¼
model_config = create_model_config("creative", api_key="sk-xxx")
runtime_config = create_runtime_config("production")

async with ChatAgent(model_config, runtime_config) as agent:
    response = await agent.chat("Hello!")
```

---

## ğŸ“ æ”¯æŒ

- ğŸ“– å®Œæ•´æ–‡æ¡£ï¼š`docs/README.md`
- ğŸ”„ æ›´æ–°æ—¥å¿—ï¼š`docs/CHANGELOG_v0.3.md`
- ğŸ’¡ ç¤ºä¾‹ä»£ç ï¼š`examples/` ç›®å½•
- ğŸ“ é…ç½®æ¨¡æ¿æ¼”ç¤ºï¼š`examples/config_templates_demo.py`

**ç‰ˆæœ¬ï¼š** v0.3.0  
**æ›´æ–°æ—¥æœŸï¼š** 2025-12-25  
**çŠ¶æ€ï¼š** âœ… ç”Ÿäº§å°±ç»ª
